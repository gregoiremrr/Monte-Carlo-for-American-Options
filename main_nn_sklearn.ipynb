{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Project\n",
    "\n",
    "## Iacob Jessica, Mourre Grégoire\n",
    "\n",
    "In this Jupter file, we will implement the different methods presented and described in https://github.com/gregoiremrr/Monte-Carlo-for-American-Options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for the lower bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "m = 12\n",
    "seed = 0\n",
    "rng = default_rng(seed=seed)\n",
    "\n",
    "r, sigma, x, K, T = 0.06, .4, 80, 100, 0.5\n",
    "dt = T/m\n",
    "\n",
    "def g(x,t=0):\n",
    "    return np.exp(-r*t*dt) * np.maximum(K-x,0)\n",
    "\n",
    "def phi(x):\n",
    "    # Canonical basis\n",
    "    #return np.array([1, x, x**2, x**3], dtype=object)\n",
    "    #return np.array([1, x, x**2, x**3, g(x)], dtype=object)\n",
    "    #return np.array([1, x, x**2, x**3, x**4, g(x)], dtype=object)\n",
    "    #return np.array([1, x, x**2, x**3, g(x), g(x)**2], dtype=object)\n",
    "    return np.array([1, x, x**2, x**3, g(x), g(x)**2, g(x)**3], dtype=object)\n",
    "    # Legendre's basis\n",
    "    #return np.array([1, x, (3*x**2-1)/2, (5*x**3-3*x)/2], dtype=object)\n",
    "    #return np.array([1, x, (3*x**2-1)/2, (5*x**3-3*x)/2, g(x)], dtype=object)\n",
    "    #return np.array([1, x, (3*x**2-1)/2, (5*x**3-3*x)/2, (35*x**4-30*x**2+3)/8, g(x)], dtype=object)\n",
    "    #return np.array([1, x, (3*x**2-1)/2, (5*x**3-3*x)/2, g(x), g(x)**2], dtype=object)\n",
    "    #return np.array([1, x, (3*x**2-1)/2, (5*x**3-3*x)/2, g(x), g(x)**2, g(x)**3], dtype=object)\n",
    "    # Hermite's basis\n",
    "    #return np.array([1, x, x**2-1, x**3-3*x], dtype=object)\n",
    "    #return np.array([1, x, x**2-1, x**3-3*x, g(x)], dtype=object)\n",
    "    #return np.array([1, x, x**2-1, x**3-3*x, x**4-6*x**2+3, g(x)], dtype=object)\n",
    "    #return np.array([1, x, x**2-1, x**3-3*x, g(x), g(x)**2], dtype=object)\n",
    "    #return np.array([1, x, x**2-1, x**3-3*x, g(x), g(x)**2, g(x)**3], dtype=object)\n",
    "    # Laguerre's basis\n",
    "    #return np.array([1, 1-x, (x**2-4*x+2)/2, (-x**3+9*x**2-18*x+6)/6], dtype=object)\n",
    "    #return np.array([1, 1-x, (x**2-4*x+2)/2, (-x**3+9*x**2-18*x+6)/6, g(x)], dtype=object)\n",
    "    #return np.array([1, 1-x, (x**2-4*x+2)/2, (-x**3+9*x**2-18*x+6)/6, (x**4-16*x**3+72*x**2-96*x+24)/24, g(x)], dtype=object)\n",
    "    #return np.array([1, 1-x, (x**2-4*x+2)/2, (-x**3+9*x**2-18*x+6)/6, g(x), g(x)**2], dtype=object)\n",
    "    #return np.array([1, 1-x, (x**2-4*x+2)/2, (-x**3+9*x**2-18*x+6)/6, g(x), g(x)**2, g(x)**3], dtype=object)\n",
    "l = len(phi(0))\n",
    "\n",
    "def reg(x, *alphas):\n",
    "    alpha = np.array(alphas)\n",
    "    return np.sum(alpha * phi(x))\n",
    "\n",
    "neural_network_ci = [Pipeline([('preprocessing',StandardScaler()), ('nn',MLPRegressor(hidden_layer_sizes=(3, 5, 5, 3), max_iter=5000, random_state=0))]) for _ in range(m)]\n",
    "#neural_network_ci = [Pipeline([('preprocessing',StandardScaler()), ('svr',SVR())]) for _ in range(m)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longstaff and Schwartz's algorithm\n",
    "Approximation of the Value Functions (Steps 2 to 4 in Longstaff & Schwartz's algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng(seed=seed)\n",
    "\n",
    "# Step 1\n",
    "B = rng.normal(size=m*n).reshape(m,n)\n",
    "X = np.cumprod(np.concatenate([[x*np.ones(n)], 1 + r * dt + sigma * np.sqrt(dt) * B]), axis=0)\n",
    "\n",
    "# Step 2\n",
    "V2 = np.zeros(n*(m+1)).reshape((m+1),n)\n",
    "V2[-1,:] = g(X[-1,:],m)\n",
    "\n",
    "# Step 3\n",
    "alpha0 = np.zeros(l)\n",
    "for i in range(m-1, 0, -1):\n",
    "    neural_network_ci[i].fit(X[i,:].reshape(-1,1), V2[i+1,:].ravel())\n",
    "    _1 = g(X[i,:],i)\n",
    "    _2 =  neural_network_ci[i].predict(X[i,:].reshape(-1, 1))\n",
    "    V2[i,:] = _1 * (_1 >= _2) + V2[(i+1),:] * (_1 < _2)\n",
    "\n",
    "# Step 4 (not used)\n",
    "_1 = g(x)\n",
    "_2 = np.mean(V2[1,:])\n",
    "V02 = np.mean(_1 * (_1 >= _2) + V2[1,:] * (_1 < _2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longstaff & Schwartz's algorithm (Step 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 21.47304533846319\n",
      "Standard deviation: 0.12675819004468372\n",
      "Condidence interval 95%: [21.22459929 21.72149139]\n",
      "Error: 1.1570135887644952 %\n"
     ]
    }
   ],
   "source": [
    "rng = default_rng(seed=seed)\n",
    "\n",
    "# Step 5\n",
    "B2 = rng.normal(size=m*n).reshape(m,n)\n",
    "X2 = np.cumprod(np.concatenate([[x*np.ones(n)], 1 + r * dt + sigma * np.sqrt(dt) * B2]), axis=0)\n",
    "\n",
    "V3 = np.zeros(n*(m+1)).reshape((m+1),n)\n",
    "V3[-1,:] = g(X2[-1,:],m)\n",
    "\n",
    "for i in range(m-1, 0, -1):\n",
    "    _1 = g(X2[i,:],i)\n",
    "    _2 =  neural_network_ci[i].predict(X2[i,:].reshape(-1, 1))\n",
    "    V3[i,:] = _1 * (_1 >= _2) + V3[(i+1),:] * (_1 < _2)\n",
    "\n",
    "_1 = g(x)\n",
    "_2 = np.mean(V3[1,:])\n",
    "V03_ = _1 * (_1 >= _2) + V3[1,:] * (_1 < _2)\n",
    "\n",
    "V03 = np.mean(V03_)\n",
    "std = np.std(V03_)\n",
    "conv_interval = V03 + np.array([-1,1]) * 1.96 * std / np.sqrt(n)\n",
    "final_lowerbound = conv_interval[0]\n",
    "\n",
    "print(\"Estimator:\", V03)\n",
    "print(\"Standard deviation:\", std / np.sqrt(n))\n",
    "print(\"Condidence interval 95%:\", conv_interval)\n",
    "print(\"Error:\", 100 * 1.96 * std / (V03 * np.sqrt(n)), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Martingales from Approximate Value Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.591534798235138\n"
     ]
    }
   ],
   "source": [
    "# One trajectory (just to get the idea of the next reel method)\n",
    "\n",
    "rng = default_rng(seed=seed)\n",
    "\n",
    "n2 = 1000\n",
    "\n",
    "B_upperbound = rng.normal(size=m)\n",
    "X_upperbound = np.cumprod(np.concatenate([[x], 1 + r * dt + sigma * np.sqrt(dt) * B_upperbound]), axis=0)\n",
    "Normal = rng.normal(size=m*n2).reshape(m,n2)\n",
    "M = np.zeros(m+1)\n",
    "Mi = 0\n",
    "\n",
    "for i in range(1, m):\n",
    "    V_upperbound = max(g(X_upperbound[i],i), neural_network_ci[i].predict(X_upperbound[i].reshape(-1, 1)))\n",
    "    X_next = X_upperbound[i-1] * (1 + r * dt + sigma * np.sqrt(dt) * Normal[i-1,:])\n",
    "    V_Ynext = np.maximum(g(X_next,i), neural_network_ci[i].predict(X_next.reshape(-1, 1)))\n",
    "    delta = V_upperbound - np.mean(V_Ynext)\n",
    "    Mi += delta\n",
    "    M[i] = Mi\n",
    "\n",
    "X_next = X_upperbound[-2] * (1 + r * dt + sigma * np.sqrt(dt) * Normal[-1,:])\n",
    "delta = g(X_upperbound[-1],m) - np.mean(g(X_next,m))\n",
    "Mi += delta\n",
    "M[-1] = Mi\n",
    "\n",
    "V0_upperbound = np.max(g(X_upperbound,np.arange(0,m+1)) - M)\n",
    "print(V0_upperbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:19<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 21.71627734807821\n",
      "Standard deviation: 0.00891986545497708\n",
      "Condidence interval 95%: [21.69879441 21.73376028]\n",
      "Error: 0.08050613837505734 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Monte-Carlo method for n trajectories\n",
    "\n",
    "rng = default_rng(seed=seed)\n",
    "\n",
    "n2 = 1000\n",
    "\n",
    "Normal = rng.normal(size=m*n*n2).reshape(m,n2,n)\n",
    "M = np.zeros(n*(m+1)).reshape(m+1,n)\n",
    "Mi = np.zeros(n)\n",
    "\n",
    "for i in tqdm(range(1, m)):\n",
    "    V_upperbound = np.maximum(g(X2[i,:],i), neural_network_ci[i].predict(X2[i,:].reshape(-1, 1)))\n",
    "    X_next = X2[i-1,:] * (1 + r * dt + sigma * np.sqrt(dt) * Normal[i-1,:,:])\n",
    "    V_Ynext = np.maximum(g(X_next,i), neural_network_ci[i].predict(X_next.reshape(-1, 1)).reshape(n2,n))\n",
    "    Mi += V_upperbound - np.mean(V_Ynext, axis=0)\n",
    "    M[i,:] = Mi\n",
    "\n",
    "X_next = X2[-2,:] * (1 + r * dt + sigma * np.sqrt(dt) * Normal[-1,:,:])\n",
    "Mi += g(X2[-1,:],m) - np.mean(g(X_next,m), axis=0)\n",
    "M[-1,:] = Mi\n",
    "\n",
    "V0_upperbound_ = np.max(g(X2.T,np.arange(0,m+1)).T - M, axis=0)\n",
    "V0_upperbound = np.mean(V0_upperbound_)\n",
    "std_upperbound = np.std(V0_upperbound_)\n",
    "conv_interval_upperbound = V0_upperbound + np.array([-1,1]) * 1.96 * std_upperbound / np.sqrt(n)\n",
    "final_upperbound = conv_interval_upperbound[1]\n",
    "\n",
    "print(\"Estimator:\", V0_upperbound)\n",
    "print(\"Standard deviation:\", std_upperbound / np.sqrt(n))\n",
    "print(\"Condidence interval 95%:\", conv_interval_upperbound)\n",
    "print(\"Error:\", 100 * 1.96 * std_upperbound / (V0_upperbound * np.sqrt(n)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval (lower & upper bounds): [21.22459928597561, 21.733760284369968]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confidence interval (lower & upper bounds):\", [final_lowerbound, final_upperbound])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Martingales from Stopping Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:02<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 21.724349084476234\n",
      "Standard deviation: 0.006401605748968468\n",
      "Condidence interval 95%: [21.71180194 21.73689623]\n",
      "Error: 0.05775614827025647 %\n"
     ]
    }
   ],
   "source": [
    "rng = default_rng(seed=seed)\n",
    "\n",
    "# Step 1\n",
    "\n",
    "n_subpaths = 500\n",
    "Normal = rng.normal(size=m*m*n*n_subpaths).reshape(n,m,m,n_subpaths)\n",
    "\n",
    "subpaths = np.zeros(m*(m+1)*n*n_subpaths).reshape(n,m,m+1,n_subpaths)\n",
    "for k in range(n):\n",
    "    for i in range(m):\n",
    "        subpaths[k,i,i+1:,:] = X2[i,k] * np.cumprod(1 + r * dt + sigma * np.sqrt(dt) * Normal[k,i,i:,:], axis=0)\n",
    "\n",
    "subpaths_values = np.zeros(m*(m+1)*n*n_subpaths).reshape(n,m,m+1,n_subpaths)\n",
    "for i in tqdm(range(m)):\n",
    "    subpaths_values[:,i,m,:] = g(subpaths[:,i,m,:],m)\n",
    "    for j in range(m-1,i,-1):\n",
    "        _1 = g(subpaths[:,i,j,:],j)\n",
    "        _2 = neural_network_ci[j].predict(subpaths[:,i,j,:].reshape(-1, 1)).reshape(n,n_subpaths)\n",
    "        subpaths_values[:,i,j,:] =  _1 * (_1 >= _2) + subpaths_values[:,i,j+1,:] * (_1 < _2)\n",
    "\n",
    "# approximation of E[ h_{\\tau_{i+1}}(X_{\\tau_{i+1}}) | X_i ] = V_iplus1[:,i]\n",
    "V_iplus1 = np.zeros(n*m).reshape(n,m)\n",
    "for i in range(m):\n",
    "    V_iplus1[:,i] = np.mean(subpaths_values[:,i,i+1,:], axis = 1)\n",
    "\n",
    "# approximation of E[ h_{\\tau_i}(X_{\\tau_i}) | X_i ] = V_i[:,i]\n",
    "V_i = np.zeros(n*(m+1)).reshape(n,m+1)\n",
    "for i in range(1,m):\n",
    "    _1 = g(X2[i,:],i)\n",
    "    _2 = neural_network_ci[i].predict(X2[i,:].reshape(-1, 1))\n",
    "    V_i[:,i] = _1 * (_1 >= _2) + V_iplus1[:,i] * (_1 < _2)\n",
    "\n",
    "V_i[:,m] = g(X2[m,:],m)\n",
    "\n",
    "Mk = np.zeros(n)\n",
    "M2 = np.zeros(n*(m+1)).reshape(n,m+1)\n",
    "for i in range(1,m+1):\n",
    "    Mk += V_i[:,i] - V_iplus1[:,i-1]\n",
    "    M2[:,i] = Mk\n",
    "\n",
    "V0_upperbound2_ = np.max(g(X2.T,np.arange(0,m+1)).T - M2.T, axis=0)\n",
    "V0_upperbound2 = np.mean(V0_upperbound2_)\n",
    "std_upperbound2 = np.std(V0_upperbound2_)\n",
    "conv_interval_upperbound2 = V0_upperbound2 + np.array([-1,1]) * 1.96 * std_upperbound2 / np.sqrt(n)\n",
    "final_upperbound2 = conv_interval_upperbound2[1]\n",
    "\n",
    "print(\"Estimator:\", V0_upperbound2)\n",
    "print(\"Standard deviation:\", std_upperbound2 / np.sqrt(n))\n",
    "print(\"Condidence interval 95%:\", conv_interval_upperbound2)\n",
    "print(\"Error:\", 100 * 1.96 * std_upperbound2 / (V0_upperbound2 * np.sqrt(n)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval (lower & upper bounds): [1, 21.733760284369968]\n",
      "Standard deviation: 0.00891986545497708\n",
      "Confidence interval (lower & upper bounds): [1, 21.73689623174421]\n",
      "Standard deviation 2: 0.006401605748968468\n"
     ]
    }
   ],
   "source": [
    "print(\"Confidence interval (lower & upper bounds):\", [1, final_upperbound])#final_lowerbound\n",
    "print(\"Standard deviation:\", std_upperbound / np.sqrt(n))\n",
    "print(\"Confidence interval (lower & upper bounds):\", [1, final_upperbound2])#final_lowerbound\n",
    "print(\"Standard deviation 2:\", std_upperbound2 / np.sqrt(n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
